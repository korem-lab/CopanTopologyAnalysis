{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make JSON of link info for each node in GFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "GFA_F = \"copan_0.gfa\"\n",
    "NODE_INFO_DICT = GFA_F.replace(\".gfa\", \"_links.json\")\n",
    "\n",
    "def main():\n",
    "    n_seg = 0\n",
    "    n_links = 0\n",
    "    n_node = 0\n",
    "    node_dict = {}\n",
    "\n",
    "    with open(GFA_F, 'r') as f:\n",
    "        for line in f:\n",
    "\n",
    "            line = re.split(\"\\t|:\", line)\n",
    "\n",
    "            if line[0] == \"S\":\n",
    "                node = line[1]\n",
    "                seq = line[2]\n",
    "                contig = line[5]\n",
    "                sample = line[6]\n",
    "                source_position = line[8]\n",
    "                end_position = line[9]\n",
    "                orientation = line[10].strip()\n",
    "                n_seg +=1\n",
    "\n",
    "                if node not in node_dict.keys():\n",
    "                    node_dict[node]= {\"seqs\": [seq], \n",
    "                                    \"contigs\": [contig], \n",
    "                                    \"samples\": [sample], \n",
    "                                    \"orientations\": [orientation], \n",
    "                                    \"links\":{}}\n",
    "                    n_node += 1\n",
    "                elif node in node_dict.keys():\n",
    "                    # possible issue: this allows for redundant info in the nested dictionaries if there are multiple seqs \n",
    "                    # belonging to the same node that also come from the same sample or contig\n",
    "                    node_dict[node][\"seqs\"].append(seq)\n",
    "                    node_dict[node][\"contigs\"].append(contig)\n",
    "                    node_dict[node][\"samples\"].append(sample)\n",
    "                    node_dict[node][\"orientations\"].append(orientation) \n",
    "\n",
    "            \n",
    "            if line[0] == \"L\":\n",
    "                n_links += 1\n",
    "                node_1 = line[1]\n",
    "                node_1_orientation = line[2]\n",
    "                node_2 = line[3]\n",
    "                node_2_orientation = line[4]\n",
    "\n",
    "                if node_1 in node_dict.keys():\n",
    "                    node_dict[node_1][\"links\"][node_2] = {\"target_orientation\": node_2_orientation, \n",
    "                                                            \"source_orientation\": node_1_orientation}\n",
    "                if node_2 in node_dict.keys():\n",
    "                    node_1_revcomp_orientation = reverse_complement(node_1_orientation)\n",
    "                    node_2_revcomp_orientation = reverse_complement(node_2_orientation)\n",
    "                    # orientation for the target and source are flipped because this represents the reverse complement link\n",
    "                    node_dict[node_2][\"links\"][node_1] = {\"target_orientation\": node_1_revcomp_orientation, \n",
    "                                                            \"source_orientation\": node_2_revcomp_orientation}\n",
    "    \n",
    "    with open(NODE_INFO_DICT, 'w') as f:\n",
    "        json.dump(node_dict, f, indent=4)\n",
    "\n",
    "\n",
    "def reverse_complement(forward_orientation):\n",
    "    if forward_orientation == \"-\":\n",
    "        return \"+\"\n",
    "    else:\n",
    "        return \"-\"\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform random walks through the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "walk number:  0\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C']]\n",
      "walk number:  1\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C']]\n",
      "B\n",
      "walk number:  0\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C']]\n",
      "walk number:  1\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C']]\n",
      "C\n",
      "walk number:  0\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C']]\n",
      "walk number:  1\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']], [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['B', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C'], ['C', 'E', 'D', 'A', 'B']]\n",
      "D\n",
      "walk number:  0\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']], [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['B', '+']]], 'D': [[['D', '+'], ['A', '+'], ['B', '+'], ['D', '-'], ['E', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C'], ['C', 'E', 'D', 'A', 'B'], ['D', 'A', 'B', 'D', 'E']]\n",
      "walk number:  1\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']], [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['B', '+']]], 'D': [[['D', '+'], ['A', '+'], ['B', '+'], ['D', '-'], ['E', '+']], [['D', '+'], ['B', '-'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C'], ['C', 'E', 'D', 'A', 'B'], ['D', 'A', 'B', 'D', 'E'], ['D', 'B', 'C']]\n",
      "E\n",
      "walk number:  0\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']], [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['B', '+']]], 'D': [[['D', '+'], ['A', '+'], ['B', '+'], ['D', '-'], ['E', '+']], [['D', '+'], ['B', '-'], ['C', '+']]], 'E': [[['E', '+'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C'], ['C', 'E', 'D', 'A', 'B'], ['D', 'A', 'B', 'D', 'E'], ['D', 'B', 'C'], ['E', 'C']]\n",
      "walk number:  1\n",
      "walk with orientation:  {'A': [[['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']], [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]], 'B': [[['B', '-'], ['C', '+']], [['B', '-'], ['C', '+']]], 'C': [[['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']], [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['B', '+']]], 'D': [[['D', '+'], ['A', '+'], ['B', '+'], ['D', '-'], ['E', '+']], [['D', '+'], ['B', '-'], ['C', '+']]], 'E': [[['E', '+'], ['C', '+']], [['E', '+'], ['C', '+']]]}\n",
      "walk without orientation:  [['A', 'D', 'E', 'C'], ['A', 'D', 'E', 'C'], ['B', 'C'], ['B', 'C'], ['C', 'B', 'D', 'E', 'C'], ['C', 'E', 'D', 'A', 'B'], ['D', 'A', 'B', 'D', 'E'], ['D', 'B', 'C'], ['E', 'C'], ['E', 'C']]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "\n",
    "NODE_INFO_DICT_F = \"dummy_graph_links.json\"\n",
    "WALKS_DICT_F = NODE_INFO_DICT_F.replace(\"links\", \"walks\")\n",
    "    \n",
    "# set walk params\n",
    "walk_length = 5 # number of nodes in walk\n",
    "n_walks = 2 # number of walks to perform per node\n",
    "\n",
    "\n",
    "# Iter through nodes in node_dict\n",
    "def main():\n",
    "    with open(NODE_INFO_DICT_F, 'r') as f:\n",
    "        node_dict = json.load(f)\n",
    "\n",
    "    walks_dict = {}\n",
    "    walks_noOrientation = []\n",
    "\n",
    "    for start_node in node_dict.keys():\n",
    "        print(start_node)\n",
    "        walk_counter = 0\n",
    "\n",
    "        walks_dict[start_node] = []\n",
    "\n",
    "        while walk_counter < n_walks:\n",
    "            print(\"walk number: \", walk_counter)\n",
    "            walk_counter = take_walk(node_dict, walks_dict, start_node, walk_counter, walks_noOrientation)\n",
    "    \n",
    "    \n",
    "    with open(WALKS_DICT_F, 'w') as f:\n",
    "        json.dump(walks_dict, f, indent=4)\n",
    "\n",
    "\n",
    "def take_walk(node_dict, walks_dict, start_node, walk_counter, walks_noOrientation):\n",
    "    node_counter = 0\n",
    "\n",
    "    # pick random link from list of links for this start node\n",
    "    linked_nodes = list(node_dict[start_node][\"links\"].keys())\n",
    "\n",
    "    if len(linked_nodes) == 0:\n",
    "        path_wOrientation = []\n",
    "        path_noOrientation = []\n",
    "\n",
    "    else: \n",
    "        # for the first step in the path, we can ignore the orientation of the first node. hence, why we call take_step here\n",
    "        next_node = random.choice(linked_nodes)\n",
    "        next_node_orientation = node_dict[start_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "        start_node_orientation = node_dict[start_node][\"links\"][next_node][\"source_orientation\"]\n",
    "\n",
    "        path_wOrientation = [[start_node, start_node_orientation], [next_node, next_node_orientation]]\n",
    "        path_noOrientation = [start_node, next_node]\n",
    "\n",
    "        node_counter += 1\n",
    "\n",
    "        paths = take_step(node_dict, walks_dict, next_node, next_node_orientation, node_counter, walk_counter, start_node, path_wOrientation, path_noOrientation)\n",
    "\n",
    "        path_wOrientation = paths[0]\n",
    "        path_noOrientation = paths[1]\n",
    "\n",
    "    walks_dict[start_node].append(path_wOrientation)\n",
    "    walks_noOrientation.append(path_noOrientation)\n",
    "\n",
    "    print(\"walk with orientation: \", walks_dict)\n",
    "    print(\"walk without orientation: \", walks_noOrientation)\n",
    "\n",
    "    return walk_counter + 1\n",
    "    \n",
    "\n",
    "def take_step(node_dict, walks_dict, source_node, source_orientation, node_counter, walk_counter, start_node, path_wOrientation, path_noOrientation):\n",
    "    while node_counter < walk_length -1:\n",
    "        linked_nodes = [linked_node for linked_node in node_dict[source_node][\"links\"] if node_dict[source_node][\"links\"][linked_node][\"source_orientation\"] == source_orientation]\n",
    "\n",
    "        if len(linked_nodes) == 0:\n",
    "            return [path_wOrientation, path_noOrientation]\n",
    "\n",
    "        else: \n",
    "            next_node = random.choice(linked_nodes)\n",
    "            next_node_orientation = node_dict[source_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "            path_wOrientation.append([next_node, next_node_orientation])\n",
    "            path_noOrientation.append(next_node)\n",
    "\n",
    "            node_counter += 1\n",
    "\n",
    "            source_node = next_node\n",
    "            source_orientation = next_node_orientation\n",
    "\n",
    "    return [path_wOrientation, path_noOrientation]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random walks with transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "NODE_INFO_DICT_F = \"dummy_graph_links.json\"\n",
    "    \n",
    "# set walk params\n",
    "walk_length = 5 # number of nodes in walk (doesn't include starting node)\n",
    "n_walks = 2 # number of walks to perform per node\n",
    "p = 1\n",
    "q = 1\n",
    "seed = 1  # set seed for later use of random.choice() for reproducibility \n",
    "\n",
    "# name output file for walks_dict to include the walk length (\"Lw\") and number of walks (\"Nw\")\n",
    "path_addon = str(walk_length) + \"Lw\" + str(n_walks) + \"Nw\" + str(p) + p \"_walks\"\n",
    "\n",
    "WALKS_DICT_F = NODE_INFO_DICT_F.replace(\"links\", path_addon)\n",
    "\n",
    "\n",
    "# Iter through nodes in node_dict\n",
    "def main():\n",
    "    with open(NODE_INFO_DICT_F, 'r') as f:\n",
    "        node_dict = json.load(f)\n",
    "\n",
    "    walks_dict = {}\n",
    "\n",
    "    for start_node in node_dict.keys():\n",
    "        print(start_node)\n",
    "        walk_counter = 0\n",
    "        walks_dict[start_node] = []\n",
    "\n",
    "        walks_dict = take_walk(node_dict, walks_dict, start_node, walk_counter)\n",
    "    \n",
    "    \n",
    "    with open(WALKS_DICT_F, 'w') as f:\n",
    "        json.dump(walks_dict, f, indent=4)\n",
    "\n",
    "\n",
    "def take_walk(node_dict, walks_dict, start_node, walk_counter):\n",
    "    while walk_counter < n_walks:\n",
    "        seed += 1  # don't want to replicate walks, so changing seed for each walk\n",
    "        node_counter = 0\n",
    "\n",
    "        # pick random link from list of links for this start node\n",
    "        neighbors = list(node_dict[start_node][\"links\"].keys())\n",
    "\n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "\n",
    "        else: \n",
    "            # for the first step in the path, we can ignore the orientation of the first node. hence, why we call take_step here\n",
    "            random.seed(seed)\n",
    "            next_node = random.choice(neighbors)\n",
    "            next_node_orientation = node_dict[start_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "            start_node_orientation = node_dict[start_node][\"links\"][next_node][\"source_orientation\"]\n",
    "\n",
    "            path = [[start_node, start_node_orientation], [next_node, next_node_orientation]]\n",
    "\n",
    "            node_counter += 1\n",
    "\n",
    "            path_result = take_step(node_dict, walks_dict, next_node, next_node_orientation, node_counter, walk_counter, start_node, start_node_orientation, path, p, q)\n",
    "            path = path_result[0]\n",
    "            walk_counter = path_result[1]\n",
    "\n",
    "        walks_dict[start_node].append(path)\n",
    "\n",
    "    return walks_dict\n",
    "    \n",
    "\n",
    "def take_step(node_dict, walks_dict, curr_node, curr_orientation, node_counter, walk_counter, prev_node, prev_orientation, path, p, q):\n",
    "    while node_counter < walk_length -1:\n",
    "        transition_probabilities = {}\n",
    "\n",
    "        curr_node_neighbors = [linked_node for linked_node in node_dict[curr_node][\"links\"] if node_dict[curr_node][\"links\"][linked_node][\"source_orientation\"] == curr_orientation]\n",
    "        prev_node_neighbors = [linked_node for linked_node in node_dict[prev_node][\"links\"] if node_dict[prev_node][\"links\"][linked_node][\"source_orientation\"] == prev_orientation]\n",
    "\n",
    "\n",
    "        if len(curr_node_neighbors) == 0:\n",
    "            walk_counter += 1\n",
    "            return [path, walk_counter]\n",
    "\n",
    "        else: \n",
    "            for neighbor in curr_node_neighbors:\n",
    "                if neighbor == prev_node:\n",
    "                    # return to previous node\n",
    "                    transition_probabilities[neighbor] = 1/p\n",
    "                elif neighbor in prev_node_neighbors:\n",
    "                    # neighbor of current node is also neighbor to previous node\n",
    "                    transition_probabilities[neighbor] = 1.0\n",
    "                else:\n",
    "                    # neighbor is not previous node and not neighbor to previous node\n",
    "                    transition_probabilities[neighbor] = 1/q\n",
    "\n",
    "            # normalize probabilities\n",
    "            total_probabilities = sum(transition_probabilities.values())  # also referred to as \"Z\" value in the literature\n",
    "            normalized_transition_probabilities = {k: v / total_probabilities for k, v in transition_probabilities.items()}\n",
    "\n",
    "\n",
    "            next_node = np.random.choice(list(normalized_transition_probabilities.keys()), p=list(normalized_transition_probabilities.values()))\n",
    "            next_orientation = node_dict[curr_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "            path.append([next_node, next_orientation])\n",
    "\n",
    "            node_counter += 1\n",
    "\n",
    "            prev_node = curr_node\n",
    "            prev_orientation = curr_orientation\n",
    "\n",
    "            curr_node = next_node\n",
    "            curr_orientation = next_orientation\n",
    "\n",
    "    walk_counter += 1\n",
    "    return [path, walk_counter]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# random walks -- adding feature to write walks for Word2Vec input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "path with orientaiton: [['A', '+'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']]\n",
      "path no orientaiton: ['A', 'B', 'D', 'E', 'C']\n",
      "path with orientaiton: [['A', '-'], ['D', '-'], ['E', '+'], ['C', '+']]\n",
      "path no orientaiton: ['A', 'D', 'E', 'C']\n",
      "B\n",
      "path with orientaiton: [['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']]\n",
      "path no orientaiton: ['B', 'D', 'E', 'C']\n",
      "path with orientaiton: [['B', '-'], ['C', '+']]\n",
      "path no orientaiton: ['B', 'C']\n",
      "C\n",
      "path with orientaiton: [['C', '-'], ['B', '+'], ['D', '-'], ['E', '+'], ['C', '+']]\n",
      "path no orientaiton: ['C', 'B', 'D', 'E', 'C']\n",
      "path with orientaiton: [['C', '-'], ['E', '-'], ['D', '+'], ['A', '+'], ['A', '+']]\n",
      "path no orientaiton: ['C', 'E', 'D', 'A', 'A']\n",
      "D\n",
      "path with orientaiton: [['D', '+'], ['B', '-'], ['A', '-'], ['D', '-'], ['E', '+']]\n",
      "path no orientaiton: ['D', 'B', 'A', 'D', 'E']\n",
      "path with orientaiton: [['D', '+'], ['B', '-'], ['C', '+']]\n",
      "path no orientaiton: ['D', 'B', 'C']\n",
      "E\n",
      "path with orientaiton: [['E', '-'], ['D', '+'], ['A', '+'], ['B', '+'], ['D', '-']]\n",
      "path no orientaiton: ['E', 'D', 'A', 'B', 'D']\n",
      "path with orientaiton: [['E', '-'], ['D', '+'], ['B', '-'], ['C', '+']]\n",
      "path no orientaiton: ['E', 'D', 'B', 'C']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "NODE_INFO_DICT_F = \"copan_0_links.json\"\n",
    "DICT_OUTPUT_DIR = \"walk_dicts_wOrientation\"\n",
    "LIST_OUTPUT_DIR = \"walk_lists_noOrientation\"\n",
    "\n",
    "# set walk params\n",
    "walk_length = 80 # number of nodes in walk (doesn't include starting node)\n",
    "n_walks = 10 # number of walks to perform per node\n",
    "p = 1\n",
    "q = 1\n",
    "SEED = 1\n",
    "# name output file for walks_dict to include the walk length (\"Lw\") and number of walks (\"Nw\")\n",
    "dict_path_addon = str(walk_length) + \"Lw\" + str(n_walks) + \"Nw\" + str(p) + \"p\" + str(q) + \"q\" + \"_walks_wOrientation\"\n",
    "list_path_addon = str(walk_length) + \"Lw\" + str(n_walks) + \"Nw\" + str(p) + \"p\" + str(q) + \"q\" + \"_walks_noOrientation.txt\"\n",
    "\n",
    "WALKS_DICT_F = DICT_OUTPUT_DIR + \"/\" + NODE_INFO_DICT_F.replace(\"links\", dict_path_addon)\n",
    "WALKS_LIST_F = LIST_OUTPUT_DIR + \"/\" + NODE_INFO_DICT_F.replace(\"links.json\", list_path_addon)\n",
    "\n",
    "# Iter through nodes in node_dict\n",
    "def main():\n",
    "    with open(NODE_INFO_DICT_F, 'r') as f:\n",
    "        node_dict = json.load(f)\n",
    "\n",
    "    walks_dict_wOrientation = {}\n",
    "    walks_list_noOrientation = []\n",
    "\n",
    "    for start_node in node_dict.keys():\n",
    "        # print(\"start node: \", start_node)\n",
    "        seed = SEED  # set seed for later use of random.choice() for reproducibility \n",
    "\n",
    "        print(start_node)\n",
    "        walk_counter = 0\n",
    "        walks_dict_wOrientation[start_node] = []\n",
    "        \n",
    "\n",
    "        walks = take_walk(node_dict, walks_dict_wOrientation, start_node, walk_counter, seed, walks_list_noOrientation)\n",
    "        walks_dict_wOrientation = walks[0]\n",
    "        walks_list_noOrientation = walks[1]\n",
    "    \n",
    "    \n",
    "    with open(WALKS_DICT_F, 'w') as f:\n",
    "        json.dump(walks_dict_wOrientation, f, indent=4)\n",
    "    \n",
    "    with open(WALKS_LIST_F, 'w') as f:\n",
    "        for walk in walks_list_noOrientation:\n",
    "            # Join the elements of the nested list into a single string\n",
    "            line = ', '.join(map(str, walk))  # Convert each element to a string and join with a comma\n",
    "            f.write(line + '\\n')  # Write the line to the file and add a newline\n",
    "        \n",
    "\n",
    "def take_walk(node_dict, walks_dict_wOrientation, start_node, walk_counter, seed, walks_list_noOrientation):\n",
    "    while walk_counter < n_walks:\n",
    "        seed += 1  # don't want to replicate walks, so changing seed for each walk\n",
    "        node_counter = 0\n",
    "\n",
    "        # pick random link from list of links for this start node\n",
    "        neighbors = list(node_dict[start_node][\"links\"].keys())\n",
    "\n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "\n",
    "        else: \n",
    "            # for the first step in the path, we can ignore the orientation of the first node. hence, why we call take_step here\n",
    "            # np.random.seed(seed)\n",
    "            next_node = np.random.choice(neighbors)\n",
    "            next_node_orientation = node_dict[start_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "            start_node_orientation = node_dict[start_node][\"links\"][next_node][\"source_orientation\"]\n",
    "\n",
    "            path_wOrientation = [[start_node, start_node_orientation], [next_node, next_node_orientation]]\n",
    "            path_noOrientation = [start_node, next_node]\n",
    "\n",
    "            node_counter += 1\n",
    "\n",
    "            paths = take_step(node_dict, next_node, next_node_orientation, node_counter, walk_counter, start_node, start_node_orientation, path_wOrientation, path_noOrientation, p, q, seed)\n",
    "            path_wOrientation = paths[0]\n",
    "            path_noOrientation = paths[1]\n",
    "            walk_counter = paths[2]\n",
    "\n",
    "        walks_dict_wOrientation[start_node].append(path_wOrientation)\n",
    "        walks_list_noOrientation.append(path_noOrientation)\n",
    "\n",
    "        print(\"path with orientaiton:\", path_wOrientation)\n",
    "        print(\"path no orientaiton:\", path_noOrientation)\n",
    "\n",
    "    return [walks_dict_wOrientation, walks_list_noOrientation]\n",
    "    \n",
    "\n",
    "def take_step(node_dict, curr_node, curr_orientation, node_counter, walk_counter, prev_node, prev_orientation, path_wOrientation, path_noOrientation, p, q, seed):\n",
    "    while node_counter < walk_length -1:\n",
    "        transition_probabilities = {}\n",
    "\n",
    "        curr_node_neighbors = [linked_node for linked_node in node_dict[curr_node][\"links\"] if node_dict[curr_node][\"links\"][linked_node][\"source_orientation\"] == curr_orientation]\n",
    "        prev_node_neighbors = [linked_node for linked_node in node_dict[prev_node][\"links\"] if node_dict[prev_node][\"links\"][linked_node][\"source_orientation\"] == prev_orientation]\n",
    "\n",
    "\n",
    "        if len(curr_node_neighbors) == 0:\n",
    "            walk_counter += 1\n",
    "\n",
    "            return [path_wOrientation, path_noOrientation, walk_counter]\n",
    "\n",
    "        else: \n",
    "            for neighbor in curr_node_neighbors:\n",
    "                if neighbor == prev_node:\n",
    "                    # return to previous node\n",
    "                    transition_probabilities[neighbor] = 1/p\n",
    "                elif neighbor in prev_node_neighbors:\n",
    "                    # neighbor of current node is also neighbor to previous node\n",
    "                    transition_probabilities[neighbor] = 1.0\n",
    "                else:\n",
    "                    # neighbor is not previous node and not neighbor to previous node\n",
    "                    transition_probabilities[neighbor] = 1/q\n",
    "\n",
    "            # normalize probabilities\n",
    "            total_probabilities = sum(transition_probabilities.values())  # also referred to as \"Z\" value in the literature\n",
    "            normalized_transition_probabilities = {k: v / total_probabilities for k, v in transition_probabilities.items()}\n",
    "\n",
    "            # np.random.seed(seed)\n",
    "            next_node = np.random.choice(list(normalized_transition_probabilities.keys()), p=list(normalized_transition_probabilities.values()))\n",
    "            next_orientation = node_dict[curr_node][\"links\"][next_node][\"target_orientation\"]\n",
    "\n",
    "            path_wOrientation.append([next_node, next_orientation])\n",
    "            path_noOrientation.append(next_node)\n",
    "\n",
    "            node_counter += 1\n",
    "\n",
    "            prev_node = curr_node\n",
    "            prev_orientation = curr_orientation\n",
    "\n",
    "            curr_node = next_node\n",
    "            curr_orientation = next_orientation\n",
    "\n",
    "    walk_counter += 1\n",
    "\n",
    "    return [path_wOrientation, path_noOrientation, walk_counter]\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stellargraph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q_/t7cl81x562sf81vt_hd37ssm0000gn/T/ipykernel_38648/3377746987.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstellargraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBiasedRandomWalk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstellargraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStellarGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstellargraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stellargraph'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stellargraph.data import BiasedRandomWalk\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph import datasets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "dataset = datasets.Cora()\n",
    "display(HTML(dataset.description))\n",
    "G, node_subjects = dataset.load(largest_connected_component_only=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
